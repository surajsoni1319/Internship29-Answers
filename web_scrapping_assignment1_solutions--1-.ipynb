{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question 1 - display all the header tags from \n",
    "‘en.wikipedia.org/wiki/Main_Page’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h1 Main Page',\n",
       " \"h2 From today's featured article\",\n",
       " 'h2 Did you know\\xa0...',\n",
       " 'h2 In the news',\n",
       " 'h2 On this day',\n",
       " \"h2 From today's featured list\",\n",
       " \"h2 Today's featured picture\",\n",
       " 'h2 Other areas of Wikipedia',\n",
       " \"h2 Wikipedia's sister projects\",\n",
       " 'h2 Wikipedia languages',\n",
       " 'h2 Navigation menu',\n",
       " 'h3 Personal tools',\n",
       " 'h3 Namespaces',\n",
       " 'h3 Variants\\nexpanded\\ncollapsed',\n",
       " 'h3 Views',\n",
       " 'h3 More\\nexpanded\\ncollapsed',\n",
       " 'h3 Search',\n",
       " 'h3 Navigation',\n",
       " 'h3 Contribute',\n",
       " 'h3 Tools',\n",
       " 'h3 Print/export',\n",
       " 'h3 In other projects',\n",
       " 'h3 Languages']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "page = requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "\n",
    "# page content\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "header_tags = [] # empty list\n",
    "for header in soup.find_all([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\",\"h6\"]):\n",
    "    header_tags.append(header.name+\" \"+header.text.strip())\n",
    "    \n",
    "# print all header_tags\n",
    "header_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question 2 - IMDB’s Top rated 100 movies’ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movies_name</th>\n",
       "      <th>year_of_release</th>\n",
       "      <th>IMDB_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>1959</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>1971</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Snatch</td>\n",
       "      <td>2000</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Le fabuleux destin d'Amélie Poulain</td>\n",
       "      <td>2001</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Kid</td>\n",
       "      <td>1921</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            movies_name year_of_release  IMDB_rating\n",
       "0              The Shawshank Redemption            1994          9.3\n",
       "1                         The Godfather            1972          9.2\n",
       "2                The Godfather: Part II            1974          9.0\n",
       "3                       The Dark Knight            2008          9.0\n",
       "4                          12 Angry Men            1957          9.0\n",
       "..                                  ...             ...          ...\n",
       "95                   North by Northwest            1959          8.3\n",
       "96                   A Clockwork Orange            1971          8.3\n",
       "97                               Snatch            2000          8.2\n",
       "98  Le fabuleux destin d'Amélie Poulain            2001          8.3\n",
       "99                              The Kid            1921          8.3\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.imdb.com/list/ls091520106/\"\n",
    "page2 = requests.get(url)\n",
    "\n",
    "#see page content\n",
    "soup2 = BeautifulSoup(page2.content)\n",
    "\n",
    "# top Movies name\n",
    "name = soup2.find_all(\"h3\", class_=\"lister-item-header\")\n",
    "# get text from movie name web elements\n",
    "movies_name = [] #empty list\n",
    "for i in name:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        movies_name.append(j.text)\n",
    "\n",
    "\n",
    "# Year of release\n",
    "year = soup2.find_all(\"span\",class_=\"lister-item-year text-muted unbold\")\n",
    "year_of_release = [] #empty list\n",
    "for k in year:\n",
    "    a=k.text.replace('(','')\n",
    "    year_of_release.append(a.replace(')','')) \n",
    "\n",
    "\n",
    "      \n",
    "# IMDB Rating\n",
    "rating = soup2.find_all(\"div\",class_=\"ipl-rating-star small\")\n",
    "\n",
    "# scrape text from rating web element\n",
    "IMDB_rating = [] #empty list\n",
    "for i in rating:\n",
    "      IMDB_rating.append(float(i.text))\n",
    "# Make data frame of top 100 movies on IMDB\n",
    "IMDB_top_100=pd.DataFrame({})\n",
    "IMDB_top_100['movies_name']=movies_name\n",
    "IMDB_top_100['year_of_release']=year_of_release\n",
    "IMDB_top_100['IMDB_rating']=IMDB_rating  \n",
    "IMDB_top_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question-3 IMDB’s Top rated 100 Indian movies’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movies_name</th>\n",
       "      <th>year_of_release</th>\n",
       "      <th>IMDB_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rang De Basanti</td>\n",
       "      <td>2006</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>2009</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taare Zameen Par</td>\n",
       "      <td>2007</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dil Chahta Hai</td>\n",
       "      <td>2001</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Swades: We, the People</td>\n",
       "      <td>2004</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Wake Up Sid</td>\n",
       "      <td>2009</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Rangeela</td>\n",
       "      <td>1995</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Shatranj Ke Khilari</td>\n",
       "      <td>1977</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Pyaar Ka Punchnama</td>\n",
       "      <td>2011</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ek Hasina Thi</td>\n",
       "      <td>2004</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               movies_name year_of_release  IMDB_rating\n",
       "0          Rang De Basanti            2006          8.1\n",
       "1                 3 Idiots            2009          8.4\n",
       "2         Taare Zameen Par            2007          8.4\n",
       "3           Dil Chahta Hai            2001          8.1\n",
       "4   Swades: We, the People            2004          8.2\n",
       "..                     ...             ...          ...\n",
       "95             Wake Up Sid            2009          7.6\n",
       "96                Rangeela            1995          7.5\n",
       "97     Shatranj Ke Khilari            1977          7.7\n",
       "98      Pyaar Ka Punchnama            2011          7.6\n",
       "99           Ek Hasina Thi            2004          7.5\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.imdb.com/list/ls009997493/\"\n",
    "page3 = requests.get(url)\n",
    "\n",
    "# check the page content\n",
    "soup3 = BeautifulSoup(page3.content)\n",
    "\n",
    "# top Movies name\n",
    "name = soup3.find_all(\"h3\", class_=\"lister-item-header\")\n",
    "# get text from movie name web elements\n",
    "movies_name = [] #empty list\n",
    "for i in name:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        movies_name.append(j.text)\n",
    "\n",
    "\n",
    "# Year of release\n",
    "year = soup3.find_all(\"span\",class_=\"lister-item-year text-muted unbold\")\n",
    "year_of_release = [] #empty list\n",
    "\n",
    "for k in year:\n",
    "    a=k.text.replace('(','')\n",
    "    year_of_release.append(a.replace(')','')) \n",
    "    \n",
    "\n",
    "# IMDB Rating\n",
    "rating = soup3.find_all(\"div\",class_=\"ipl-rating-star small\")\n",
    "\n",
    "# scrape text from rating web element\n",
    "IMDB_rating = [] #empty list\n",
    "for i in rating:\n",
    "      IMDB_rating.append(float(i.text))\n",
    "# Make data frame of top 100 India imdb movies\n",
    "indian_top_100=pd.DataFrame({})\n",
    "indian_top_100['movies_name']=movies_name\n",
    "indian_top_100['year_of_release']=year_of_release\n",
    "indian_top_100['IMDB_rating']=IMDB_rating\n",
    "indian_top_100    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4 - Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) \n",
    "from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Term of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name  \\\n",
       "0          Shri Pranab Mukherjee    \n",
       "1   Smt Pratibha Devisingh Patil    \n",
       "2         DR. A.P.J. Abdul Kalam    \n",
       "3           Shri K. R. Narayanan    \n",
       "4        Dr Shankar Dayal Sharma    \n",
       "5            Shri R Venkataraman    \n",
       "6               Giani Zail Singh    \n",
       "7      Shri Neelam Sanjiva Reddy    \n",
       "8       Dr. Fakhruddin Ali Ahmed    \n",
       "9   Shri Varahagiri Venkata Giri    \n",
       "10              Dr. Zakir Husain    \n",
       "11  Dr. Sarvepalli Radhakrishnan    \n",
       "12           Dr. Rajendra Prasad    \n",
       "\n",
       "                                       Term of Office  \n",
       "0                     25 July, 2012 to 25 July, 2017   \n",
       "1                     25 July, 2007 to 25 July, 2012   \n",
       "2                     25 July, 2002 to 25 July, 2007   \n",
       "3                     25 July, 1997 to 25 July, 2002   \n",
       "4                     25 July, 1992 to 25 July, 1997   \n",
       "5                     25 July, 1987 to 25 July, 1992   \n",
       "6                     25 July, 1982 to 25 July, 1987   \n",
       "7                     25 July, 1977 to 25 July, 1982   \n",
       "8                24 August, 1974 to 11 February, 1977  \n",
       "9    3 May, 1969 to 20 July, 1969 and 24 August, 1...  \n",
       "10                        13 May, 1967 to 3 May, 1969  \n",
       "11                       13 May, 1962 to 13 May, 1967  \n",
       "12                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page4 = requests.get(\"https://presidentofindia.nic.in/former-presidents.htm\")\n",
    "\n",
    "# page content\n",
    "soup4=BeautifulSoup(page4.content)\n",
    "\n",
    "# scraping the name\n",
    "name = [] # creating empty list\n",
    "for i in soup4.find_all(\"div\",class_=\"presidentListing\"): \n",
    "    name.append(i.find(\"h3\").text.split(\"(\")[0])\n",
    "    \n",
    "# scraping term of office\n",
    "office = [] # creating the empty list\n",
    "    \n",
    "for i in soup4.find_all(\"div\",class_=\"presidentListing\"):\n",
    "     office.append(i.find_all(\"p\")[0].text.split(\":\")[1])\n",
    "        \n",
    "    \n",
    "data = list(zip(name,office))                                           #zipping data\n",
    "df = pd.DataFrame(data,columns=[\"Name\",\"Term of Office\"])                    #Creating Dataset    \n",
    "df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5- Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* i) Top 10 ODI teams in men’s cricket along with the records for matches, points and \n",
    "rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_name</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>25</td>\n",
       "      <td>2,945</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>29</td>\n",
       "      <td>3,344</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England</td>\n",
       "      <td>27</td>\n",
       "      <td>3,100</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>20</td>\n",
       "      <td>2,137</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>24</td>\n",
       "      <td>2,323</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>24</td>\n",
       "      <td>2,157</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>27</td>\n",
       "      <td>2,222</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>21</td>\n",
       "      <td>1,652</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>17</td>\n",
       "      <td>1,054</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team_name Matches Points  \\\n",
       "0   New Zealand      17  2,054   \n",
       "1     Australia      25  2,945   \n",
       "2         India      29  3,344   \n",
       "3       England      27  3,100   \n",
       "4  South Africa      20  2,137   \n",
       "5      Pakistan      24  2,323   \n",
       "6    Bangladesh      24  2,157   \n",
       "7   West Indies      27  2,222   \n",
       "8     Sri Lanka      21  1,652   \n",
       "9   Afghanistan      17  1,054   \n",
       "\n",
       "                                             Ratings  \n",
       "0                              121               ...  \n",
       "1                                                118  \n",
       "2                                                115  \n",
       "3                                                115  \n",
       "4                                                107  \n",
       "5                                                 97  \n",
       "6                                                 90  \n",
       "7                                                 82  \n",
       "8                                                 79  \n",
       "9                                                 62  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "page5 = requests.get(url)\n",
    "# see content in page5\n",
    "soup5 = BeautifulSoup(page5.content)\n",
    "#scrape team names\n",
    "team = soup5.find_all(\"span\",class_='u-hide-phablet')\n",
    "team_name = []\n",
    "for i in team:\n",
    "    team_name.append(i.text)\n",
    "matches = [] #empty list\n",
    "points = [] #empty list\n",
    "ratings = [] #empty list\n",
    "new_list = [] #empty list\n",
    "\n",
    "for i in soup5.find_all(\"td\",class_='rankings-block__banner--matches'): # first place team number of matches\n",
    "    matches.append(i.text)\n",
    "for i in soup5.find_all(\"td\",class_='rankings-block__banner--points'):# first place team points\n",
    "    points.append(i.text)\n",
    "for i in soup5.find_all(\"td\",class_='rankings-block__banner--rating u-text-right'):# first place team ratings\n",
    "    ratings.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell u-center-text'):# other teams number of matches and points\n",
    "    new_list.append(i.text)\n",
    "for i in range(0,len(new_list)-1,2):\n",
    "    matches.append(new_list[i]) # other teams matches\n",
    "    points.append(new_list[i+1]) # other teams points\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell u-text-right rating'):# other teams ratings\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "# Make data frame of top 10 ICC teams\n",
    "icc=pd.DataFrame({})\n",
    "icc['Team_name']=team_name[:10]\n",
    "icc['Matches']=matches[:10]\n",
    "icc['Points']=points[:10]\n",
    "icc['Ratings']=ratings[:10]\n",
    "icc    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ii) Top 10 ODI Batsmen in men along with the records of their team and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Francois du Plessis</td>\n",
       "      <td>SA</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player                     Team Rating\n",
       "0           Babar Azam  PAK                        865\n",
       "1          Virat Kohli                      IND    857\n",
       "2         Rohit Sharma                      IND    825\n",
       "3          Ross Taylor                       NZ    801\n",
       "4          Aaron Finch                      AUS    791\n",
       "5       Jonny Bairstow                      ENG    785\n",
       "6         Fakhar Zaman                      PAK    778\n",
       "7  Francois du Plessis                       SA    778\n",
       "8         David Warner                      AUS    773\n",
       "9            Shai Hope                       WI    773"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "page6 = requests.get(url)\n",
    "# see content in page6\n",
    "soup6 = BeautifulSoup(page6.content)\n",
    "players = [] #empty list\n",
    "team_name = [] #empty list\n",
    "rating = [] #empty list\n",
    "\n",
    "for i in soup6.find_all(\"div\",class_='rankings-block__banner--name-large'): # first place player name\n",
    "    players.append(i.text)\n",
    "for i in soup6.find_all(\"div\",class_='rankings-block__banner--nationality'): # first place player team name\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup6.find_all(\"div\",class_='rankings-block__banner--rating'): # first place player rating\n",
    "    rating.append(i.text)\n",
    "for i in soup6.find_all(\"td\",class_='table-body__cell rankings-table__name name'):# players name\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup6.find_all(\"span\",class_='table-body__logo-text'): # players team name\n",
    "    team_name.append(i.text)\n",
    "for i in soup6.find_all(\"td\",class_='table-body__cell rating'): # players rating\n",
    "    rating.append(i.text)\n",
    "# Make data frame of top 10 ICC Batsmen\n",
    "Batsmen=pd.DataFrame({})\n",
    "Batsmen['Player']=players[:10]\n",
    "Batsmen['Team']=team_name[:10]\n",
    "Batsmen['Rating']=rating[:10]\n",
    "Batsmen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* iii) Top 10 ODI bowlers along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pat Cummins</td>\n",
       "      <td>AUS</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mohammad Amir</td>\n",
       "      <td>PAK</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player                    Team Rating\n",
       "0       Trent Boult  NZ                        737\n",
       "1  Mujeeb Ur Rahman                     AFG    708\n",
       "2        Matt Henry                      NZ    691\n",
       "3    Jasprit Bumrah                     IND    690\n",
       "4      Mehedi Hasan                     BAN    668\n",
       "5     Kagiso Rabada                      SA    666\n",
       "6      Chris Woakes                     ENG    665\n",
       "7    Josh Hazlewood                     AUS    660\n",
       "8       Pat Cummins                     AUS    646\n",
       "9     Mohammad Amir                     PAK    638"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "page7 = requests.get(url)\n",
    "\n",
    "# see content in page7\n",
    "soup7 = BeautifulSoup(page7.content)\n",
    "\n",
    "players = [] #empty list\n",
    "team_name = [] #empty list  \n",
    "rating = [] #empty list \n",
    "\n",
    "for i in soup7.find_all(\"div\",class_='rankings-block__banner--name-large'): # first place player name\n",
    "    players.append(i.text)\n",
    "for i in soup7.find_all(\"div\",class_='rankings-block__banner--nationality'): # first place player team name\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup7.find_all(\"div\",class_='rankings-block__banner--rating'): # first place player rating\n",
    "    rating.append(i.text)\n",
    "for i in soup7.find_all(\"td\",class_='table-body__cell rankings-table__name name'):# players name\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup7.find_all(\"span\",class_='table-body__logo-text'): # players team name\n",
    "    team_name.append(i.text)\n",
    "for i in soup7.find_all(\"td\",class_='table-body__cell rating'): # players rating\n",
    "    rating.append(i.text)\n",
    "# Make data frame of top 10 ICC bowlers\n",
    "bowlers=pd.DataFrame({})\n",
    "bowlers['Player']=players[:10]\n",
    "bowlers['Team']=team_name[:10]\n",
    "bowlers['Rating']=rating[:10]\n",
    "bowlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question 6 - Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* i) Top 10 ODI teams in women’s cricket along with the records for matches, points \n",
    "and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_name</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>18</td>\n",
       "      <td>2,955</td>\n",
       "      <td>164               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>2,828</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>17</td>\n",
       "      <td>1,993</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>20</td>\n",
       "      <td>2,226</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>21</td>\n",
       "      <td>1,947</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>12</td>\n",
       "      <td>1,025</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>15</td>\n",
       "      <td>1,101</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team_name Matches Points  \\\n",
       "0     Australia      18  2,955   \n",
       "1  South Africa      24  2,828   \n",
       "2       England      17  1,993   \n",
       "3         India      20  2,226   \n",
       "4   New Zealand      21  1,947   \n",
       "5   West Indies      12  1,025   \n",
       "6      Pakistan      15  1,101   \n",
       "7    Bangladesh       5    306   \n",
       "8     Sri Lanka      11    519   \n",
       "9       Ireland       2     25   \n",
       "\n",
       "                                             Ratings  \n",
       "0                              164               ...  \n",
       "1                                                118  \n",
       "2                                                117  \n",
       "3                                                111  \n",
       "4                                                 93  \n",
       "5                                                 85  \n",
       "6                                                 73  \n",
       "7                                                 61  \n",
       "8                                                 47  \n",
       "9                                                 13  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "page8 = requests.get(url)\n",
    "#see content in page8\n",
    "soup8 = BeautifulSoup(page8.content)\n",
    "#scrape team names\n",
    "womens_team = soup8.find_all(\"span\",class_='u-hide-phablet')\n",
    "womens_team_name = []\n",
    "for i in womens_team:\n",
    "    womens_team_name.append(i.text)\n",
    "womens_matches = [] #empty list\n",
    "womens_points = [] #empty list\n",
    "womens_ratings = [] #empty list\n",
    "womens_new_list = [] #empty list\n",
    "for i in soup8.find_all(\"td\",class_='rankings-block__banner--matches'): # first place team number of matches\n",
    "    womens_matches.append(i.text)\n",
    "for i in soup8.find_all(\"td\",class_='rankings-block__banner--points'):# first place team points\n",
    "    womens_points.append(i.text)\n",
    "for i in soup8.find_all(\"td\",class_='rankings-block__banner--rating u-text-right'):# first place team ratings\n",
    "    womens_ratings.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup8.find_all(\"td\",class_='table-body__cell u-center-text'):# other teams number of matches and points\n",
    "    womens_new_list.append(i.text)\n",
    "for i in range(0,len(womens_new_list)-1,2):\n",
    "    womens_matches.append(womens_new_list[i]) # other teams matches\n",
    "    womens_points.append(womens_new_list[i+1]) # other teams points\n",
    "for i in soup8.find_all(\"td\",class_='table-body__cell u-text-right rating'):# other teams number of matches and ratings\n",
    "    womens_ratings.append(i.text)\n",
    "# Make data frame of top 10 ICC teams\n",
    "womens_icc=pd.DataFrame({})\n",
    "womens_icc['Team_name']=womens_team_name[:10]\n",
    "womens_icc['Matches']=womens_matches[:10]\n",
    "womens_icc['Points']=womens_points[:10]\n",
    "womens_icc['Ratings']=womens_ratings[:10]\n",
    "womens_icc    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ii) Top 10 women’s ODI players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player                     Team Rating\n",
       "0     Tammy Beaumont  ENG                        765\n",
       "1        Lizelle Lee                       SA    758\n",
       "2       Alyssa Healy                      AUS    756\n",
       "3    Stafanie Taylor                       WI    746\n",
       "4        Meg Lanning                      AUS    723\n",
       "5  Amy Satterthwaite                       NZ    715\n",
       "6    Smriti Mandhana                      IND    710\n",
       "7        Mithali Raj                      IND    709\n",
       "8     Natalie Sciver                      ENG    685\n",
       "9    Laura Wolvaardt                       SA    683"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "page9 = requests.get(url)\n",
    "# see content in page9\n",
    "soup9 = BeautifulSoup(page9.content)\n",
    "players = [] #empty list\n",
    "team_name = [] #empty list\n",
    "rating = [] #empty list\n",
    "\n",
    "for i in soup9.find_all(\"div\",class_='rankings-block__banner--name-large'): # first place player name\n",
    "    players.append(i.text)\n",
    "for i in soup9.find_all(\"div\",class_='rankings-block__banner--nationality'): # first place player team name\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup9.find_all(\"div\",class_='rankings-block__banner--rating'): # first place player rating\n",
    "    rating.append(i.text)\n",
    "for i in soup9.find_all(\"td\",class_='table-body__cell rankings-table__name name'):# players name\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup9.find_all(\"span\",class_='table-body__logo-text'): # players team name\n",
    "    team_name.append(i.text)\n",
    "for i in soup9.find_all(\"td\",class_='table-body__cell rating'): # players rating\n",
    "    rating.append(i.text)\n",
    "# Make data frame of top 10 Women's ODI Batting Rankings\n",
    "top_players=pd.DataFrame({})\n",
    "top_players['Player']=players[:10]\n",
    "top_players['Team']=team_name[:10]\n",
    "top_players['Rating']=rating[:10]\n",
    "top_players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* iii)Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player                    Team Rating\n",
       "0    Marizanne Kapp  SA                        418\n",
       "1      Ellyse Perry                     AUS    418\n",
       "2   Stafanie Taylor                      WI    410\n",
       "3    Natalie Sciver                     ENG    349\n",
       "4     Deepti Sharma                     IND    343\n",
       "5     Jess Jonassen                     AUS    307\n",
       "6  Ashleigh Gardner                     AUS    252\n",
       "7  Dane van Niekerk                      SA    243\n",
       "8     Sophie Devine                      NZ    242\n",
       "9       Amelia Kerr                      NZ    236"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "page10 = requests.get(url)\n",
    "\n",
    "# see content in page10\n",
    "soup10 = BeautifulSoup(page10.content)\n",
    "\n",
    "players = [] #empty list\n",
    "team_name = [] #empty list  \n",
    "rating = [] #empty list \n",
    "\n",
    "for i in soup10.find_all(\"div\",class_='rankings-block__banner--name-large'): # first place player name\n",
    "    players.append(i.text)\n",
    "for i in soup10.find_all(\"div\",class_='rankings-block__banner--nationality'): # first place player team name\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup10.find_all(\"div\",class_='rankings-block__banner--rating'): # first place player rating\n",
    "    rating.append(i.text)\n",
    "for i in soup10.find_all(\"td\",class_='table-body__cell rankings-table__name name'):# players name\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup10.find_all(\"span\",class_='table-body__logo-text'): # players team name\n",
    "    team_name.append(i.text)\n",
    "for i in soup10.find_all(\"td\",class_='table-body__cell rating'): # players rating\n",
    "    rating.append(i.text)\n",
    "# Make data frame of top 10 ICC Women's ODI All-Rounder Rankings\n",
    "all_rounder=pd.DataFrame({})\n",
    "all_rounder['Player']=players[:10]\n",
    "all_rounder['Team']=team_name[:10]\n",
    "all_rounder['Rating']=rating[:10]\n",
    "all_rounder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "i) Headline\n",
    "ii) Time\n",
    "iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.cnbc.com/world/?region=world\"\n",
    "page7 = requests.get(url)\n",
    "# see content in page7\n",
    "soup7 = BeautifulSoup(page7.content)\n",
    "\n",
    "\n",
    "# creaing empty lists \n",
    "time = []\n",
    "headline = []\n",
    "newsLink = []\n",
    "\n",
    "#Iterating over all the news\n",
    "for i in soup7.find_all(\"div\",class_=\"LatestNews-container\"):\n",
    "     headline.append(i.find(\"a\",class_=\"LatestNews-headline\").text)  \n",
    "        \n",
    "for i in soup7.find_all(\"div\",class_=\"LatestNews-container\"):\n",
    "     time.append(i.find(\"time\").text)   \n",
    "        \n",
    "for i in soup7.find_all(\"div\",class_=\"LatestNews-container\"):\n",
    "     newsLink.append(i.find(\"a\",class_=\"LatestNews-headline\").get(\"href\"))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How Davos became the anti-establishment’s punc...</td>\n",
       "      <td>30 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/23/davos-the-worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>European markets head for higher open despite ...</td>\n",
       "      <td>35 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/23/european-marke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why Turkey is standing in the way of Sweden an...</td>\n",
       "      <td>35 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/23/why-turkey-doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China's state-backed blockchain company to lau...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/22/chinas-state-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Four 'dream jobs' for people who love to travel</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/23/jobs-for-peopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analysts predict tech's next move — and name t...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/23/tech-sector-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Time to sell or buy the dip? Here's how pros s...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/23/buy-the-dip-or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hong Kong's Hang Seng falls as tech stocks sli...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/23/asia-markets-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Oxfam slams billionaire pandemic 'bonanza,' sa...</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/22/oxfam-slams-bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stock futures rise after Dow falls for 8th-str...</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/22/stock-market-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Another baby formula shipment from Europe to a...</td>\n",
       "      <td>9 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/22/another-baby-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hyundai plans $5 billion investment in U.S. on...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/22/hyundai-plans-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SpaceX looks to raise $1.7 billion in new funding</td>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/22/elon-musks-spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Any potential recession will be 'light,' Qatar...</td>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/22/recession-will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The 4 things this mindfulness coach with a Har...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/22/the-4-things-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Covid cases are surging again—here's what to e...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/22/covid-cases-ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Student loan forgiveness could be around the c...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/22/what-to-do-whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>These stocks are good buys even if earnings ta...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/22/these-stocks-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Meet the veteran growth investor who picks sto...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/22/meet-the-veter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The 'work from anywhere' experiment got some t...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/22/our-great-hybr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Prices are surging, but fans are still paying ...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/22/inflation-is-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>U.S. roadway deaths rise, even as cars get saf...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/22/us-roadway-dea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ukraine rules out ceasefire and ceding territo...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/22/russia-ukraine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>'We're sorry' for baby formula shortage, Abbot...</td>\n",
       "      <td>May 21, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/05/21/abbott-ceo-apo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Russia just issued a list of Americans banned ...</td>\n",
       "      <td>May 21, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/05/21/russia-bans-bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6 things this immunologist does every night to...</td>\n",
       "      <td>May 21, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/05/21/6-things-this-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The founders of NYC’s first woman-owned brewer...</td>\n",
       "      <td>May 21, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/05/21/founders-of-ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>New effort aims to celebrate high school stude...</td>\n",
       "      <td>May 21, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/05/21/career-signing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Even in a hot labor market, workers are worrie...</td>\n",
       "      <td>May 21, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/05/21/even-in-a-hot-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>This 27-year-old quit her job to open a bookst...</td>\n",
       "      <td>May 21, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/05/21/career-advice-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline          Time  \\\n",
       "0   How Davos became the anti-establishment’s punc...    30 Min Ago   \n",
       "1   European markets head for higher open despite ...    35 Min Ago   \n",
       "2   Why Turkey is standing in the way of Sweden an...    35 Min Ago   \n",
       "3   China's state-backed blockchain company to lau...   4 Hours Ago   \n",
       "4    Four 'dream jobs' for people who love to travel    5 Hours Ago   \n",
       "5   Analysts predict tech's next move — and name t...   5 Hours Ago   \n",
       "6   Time to sell or buy the dip? Here's how pros s...   6 Hours Ago   \n",
       "7   Hong Kong's Hang Seng falls as tech stocks sli...   6 Hours Ago   \n",
       "8   Oxfam slams billionaire pandemic 'bonanza,' sa...   7 Hours Ago   \n",
       "9   Stock futures rise after Dow falls for 8th-str...   8 Hours Ago   \n",
       "10  Another baby formula shipment from Europe to a...   9 Hours Ago   \n",
       "11  Hyundai plans $5 billion investment in U.S. on...  10 Hours Ago   \n",
       "12  SpaceX looks to raise $1.7 billion in new funding  16 Hours Ago   \n",
       "13  Any potential recession will be 'light,' Qatar...  16 Hours Ago   \n",
       "14  The 4 things this mindfulness coach with a Har...  17 Hours Ago   \n",
       "15  Covid cases are surging again—here's what to e...  17 Hours Ago   \n",
       "16  Student loan forgiveness could be around the c...  17 Hours Ago   \n",
       "17  These stocks are good buys even if earnings ta...  17 Hours Ago   \n",
       "18  Meet the veteran growth investor who picks sto...  17 Hours Ago   \n",
       "19  The 'work from anywhere' experiment got some t...  17 Hours Ago   \n",
       "20  Prices are surging, but fans are still paying ...  18 Hours Ago   \n",
       "21  U.S. roadway deaths rise, even as cars get saf...  19 Hours Ago   \n",
       "22  Ukraine rules out ceasefire and ceding territo...  22 Hours Ago   \n",
       "23  'We're sorry' for baby formula shortage, Abbot...  May 21, 2022   \n",
       "24  Russia just issued a list of Americans banned ...  May 21, 2022   \n",
       "25  6 things this immunologist does every night to...  May 21, 2022   \n",
       "26  The founders of NYC’s first woman-owned brewer...  May 21, 2022   \n",
       "27  New effort aims to celebrate high school stude...  May 21, 2022   \n",
       "28  Even in a hot labor market, workers are worrie...  May 21, 2022   \n",
       "29  This 27-year-old quit her job to open a bookst...  May 21, 2022   \n",
       "\n",
       "                                            News Link  \n",
       "0   https://www.cnbc.com/2022/05/23/davos-the-worl...  \n",
       "1   https://www.cnbc.com/2022/05/23/european-marke...  \n",
       "2   https://www.cnbc.com/2022/05/23/why-turkey-doe...  \n",
       "3   https://www.cnbc.com/2022/05/22/chinas-state-b...  \n",
       "4   https://www.cnbc.com/2022/05/23/jobs-for-peopl...  \n",
       "5   https://www.cnbc.com/2022/05/23/tech-sector-an...  \n",
       "6   https://www.cnbc.com/2022/05/23/buy-the-dip-or...  \n",
       "7   https://www.cnbc.com/2022/05/23/asia-markets-s...  \n",
       "8   https://www.cnbc.com/2022/05/22/oxfam-slams-bi...  \n",
       "9   https://www.cnbc.com/2022/05/22/stock-market-f...  \n",
       "10  https://www.cnbc.com/2022/05/22/another-baby-f...  \n",
       "11  https://www.cnbc.com/2022/05/22/hyundai-plans-...  \n",
       "12  https://www.cnbc.com/2022/05/22/elon-musks-spa...  \n",
       "13  https://www.cnbc.com/2022/05/22/recession-will...  \n",
       "14  https://www.cnbc.com/2022/05/22/the-4-things-t...  \n",
       "15  https://www.cnbc.com/2022/05/22/covid-cases-ar...  \n",
       "16  https://www.cnbc.com/2022/05/22/what-to-do-whi...  \n",
       "17  https://www.cnbc.com/2022/05/22/these-stocks-a...  \n",
       "18  https://www.cnbc.com/2022/05/22/meet-the-veter...  \n",
       "19  https://www.cnbc.com/2022/05/22/our-great-hybr...  \n",
       "20  https://www.cnbc.com/2022/05/22/inflation-is-r...  \n",
       "21  https://www.cnbc.com/2022/05/22/us-roadway-dea...  \n",
       "22  https://www.cnbc.com/2022/05/22/russia-ukraine...  \n",
       "23  https://www.cnbc.com/2022/05/21/abbott-ceo-apo...  \n",
       "24  https://www.cnbc.com/2022/05/21/russia-bans-bi...  \n",
       "25  https://www.cnbc.com/2022/05/21/6-things-this-...  \n",
       "26  https://www.cnbc.com/2022/05/21/founders-of-ta...  \n",
       "27  https://www.cnbc.com/2022/05/21/career-signing...  \n",
       "28  https://www.cnbc.com/2022/05/21/even-in-a-hot-...  \n",
       "29  https://www.cnbc.com/2022/05/21/career-advice-...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Dataset\n",
    "data = list(zip(headline,time,newsLink))                                           #zipping data\n",
    "df = pd.DataFrame(data,columns=[\"Headline\",\"Time\",\"News Link\"])   \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape the details of most downloaded articles from AI in last 90 days. \n",
    "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape below mentioned details :\n",
    "i) Paper Title \n",
    "ii) Authors\n",
    "iii) Published Date \n",
    "iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"\n",
    "page8 = requests.get(url)\n",
    "# see content in page8\n",
    "soup8 = BeautifulSoup(page8.content)\n",
    "\n",
    "# creating empty lists\n",
    "title = []\n",
    "author = []\n",
    "date = []\n",
    "link = []\n",
    "\n",
    "# scraping required data \n",
    "for i in soup8.find_all(\"h2\",class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):\n",
    "    title.append(i.text)\n",
    "                      \n",
    "for i in soup8.find_all(\"span\",class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "    author.append(i.text)\n",
    "\n",
    "for i in soup8.find_all(\"span\",class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "    date.append(i.text)\n",
    "    \n",
    "for i in soup8.find_all(\"a\",class_=\"sc-5smygv-0 nrDZj\"):\n",
    "    link.append(i.get(\"href\"))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q9- Write a python program to scrape mentioned details from ‘https://www.dineout.co.in/delhi-restaurants/buffetspecial’ :\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "page = requests.get(\"https://www.dineout.co.in/delhi-restaurants/buffet-special\")\n",
    "# page content\n",
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-info cursor\"):\n",
    "    name.append(i.text)\n",
    "location=[]\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(i.text)\n",
    "\n",
    "price = []\n",
    "cuisine = []\n",
    "for i in soup.find_all(\"span\", class_=\"double-line-ellipsis\"):\n",
    "    price.append(i.text.split('|')[0])\n",
    "    cuisine.append(i.text.split('|')[1])\n",
    "\n",
    "rating=[]\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-rating rating-3\"):\n",
    "    rating.append(i.text)\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-rating rating-4\"):\n",
    "    rating.append(i.text)\n",
    "\n",
    "images = []\n",
    "for i in soup.find_all(\"img\", class_=\"no-img\"):\n",
    "    images.append(i['data-src'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 13 13 13 13 13\n"
     ]
    }
   ],
   "source": [
    "print(len(name), len(location), len(price), len(cuisine), len(rating), len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Price</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Rating</th>\n",
       "      <th>IMAGES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle BarbequeConnaught Place, Central Delhi</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>₹ 2,000 for 2 (approx)</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>3.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>₹ 1,400 for 2 (approx)</td>\n",
       "      <td>North Indian, Barbecue, Italian, Asian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle BarbequePacific Mall,Tagore Garden, Wes...</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>₹ 2,000 for 2 (approx)</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe KnoshThe Leela Ambience Convention Hotel,...</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>₹ 3,000 for 2 (approx)</td>\n",
       "      <td>Multi-Cuisine, North Indian, Italian, Contine...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque CompanyGardens Galleria,Sector 38...</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>₹ 1,800 for 2 (approx)</td>\n",
       "      <td>Barbecue, Chinese, Mughlai, North Indian</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India GrillHilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>₹ 2,400 for 2 (approx)</td>\n",
       "      <td>North Indian, Italian, Oriental</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>₹ 1,500 for 2 (approx)</td>\n",
       "      <td>Barbecue, North Indian</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que VillageIndirapuram Ha...</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>₹ 1,600 for 2 (approx)</td>\n",
       "      <td>North Indian, Chinese, Fast Food</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>World CafeVibe by The Lalit Traveller,Sector 3...</td>\n",
       "      <td>Vibe by The Lalit Traveller,Sector 35, Faridabad</td>\n",
       "      <td>₹ 900 for 2 (approx)</td>\n",
       "      <td>North Indian, Chinese, Continental</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indian Grill RoomSuncity Business Tower,Golf C...</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>₹ 2,200 for 2 (approx)</td>\n",
       "      <td>North Indian, Mughlai, Barbecue</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mad 4 Bar B QueSector 29, Faridabad</td>\n",
       "      <td>Sector 29, Faridabad</td>\n",
       "      <td>₹ 800 for 2 (approx)</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barbeque 29NIT, Faridabad</td>\n",
       "      <td>NIT, Faridabad</td>\n",
       "      <td>₹ 1,500 for 2 (approx)</td>\n",
       "      <td>North Indian, Chinese, Barbecue</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GlasshouseDoubleTree By Hilton Gurugram Baani ...</td>\n",
       "      <td>DoubleTree By Hilton Gurugram Baani Square,Sec...</td>\n",
       "      <td>₹ 3,400 for 2 (approx)</td>\n",
       "      <td>Multi-Cuisine, Asian, European, Italian, Nort...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Restaurant Name  \\\n",
       "0       Castle BarbequeConnaught Place, Central Delhi   \n",
       "1   Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...   \n",
       "2   Castle BarbequePacific Mall,Tagore Garden, Wes...   \n",
       "3   Cafe KnoshThe Leela Ambience Convention Hotel,...   \n",
       "4   The Barbeque CompanyGardens Galleria,Sector 38...   \n",
       "5     India GrillHilton Garden Inn,Saket, South Delhi   \n",
       "6   Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...   \n",
       "7   The Monarch - Bar Be Que VillageIndirapuram Ha...   \n",
       "8   World CafeVibe by The Lalit Traveller,Sector 3...   \n",
       "9   Indian Grill RoomSuncity Business Tower,Golf C...   \n",
       "10                Mad 4 Bar B QueSector 29, Faridabad   \n",
       "11                          Barbeque 29NIT, Faridabad   \n",
       "12  GlasshouseDoubleTree By Hilton Gurugram Baani ...   \n",
       "\n",
       "                                             Location  \\\n",
       "0                      Connaught Place, Central Delhi   \n",
       "1              3CS Mall,Lajpat Nagar - 3, South Delhi   \n",
       "2              Pacific Mall,Tagore Garden, West Delhi   \n",
       "3   The Leela Ambience Convention Hotel,Shahdara, ...   \n",
       "4                  Gardens Galleria,Sector 38A, Noida   \n",
       "5                Hilton Garden Inn,Saket, South Delhi   \n",
       "6      Taurus Sarovar Portico,Mahipalpur, South Delhi   \n",
       "7   Indirapuram Habitat Centre,Indirapuram, Ghaziabad   \n",
       "8    Vibe by The Lalit Traveller,Sector 35, Faridabad   \n",
       "9    Suncity Business Tower,Golf Course Road, Gurgaon   \n",
       "10                               Sector 29, Faridabad   \n",
       "11                                     NIT, Faridabad   \n",
       "12  DoubleTree By Hilton Gurugram Baani Square,Sec...   \n",
       "\n",
       "                      Price  \\\n",
       "0   ₹ 2,000 for 2 (approx)    \n",
       "1   ₹ 1,400 for 2 (approx)    \n",
       "2   ₹ 2,000 for 2 (approx)    \n",
       "3   ₹ 3,000 for 2 (approx)    \n",
       "4   ₹ 1,800 for 2 (approx)    \n",
       "5   ₹ 2,400 for 2 (approx)    \n",
       "6   ₹ 1,500 for 2 (approx)    \n",
       "7   ₹ 1,600 for 2 (approx)    \n",
       "8     ₹ 900 for 2 (approx)    \n",
       "9   ₹ 2,200 for 2 (approx)    \n",
       "10    ₹ 800 for 2 (approx)    \n",
       "11  ₹ 1,500 for 2 (approx)    \n",
       "12  ₹ 3,400 for 2 (approx)    \n",
       "\n",
       "                                              Cuisine Rating  \\\n",
       "0                               Chinese, North Indian    3.4   \n",
       "1              North Indian, Barbecue, Italian, Asian    3.9   \n",
       "2                               North Indian, Chinese      4   \n",
       "3    Multi-Cuisine, North Indian, Italian, Contine...    4.3   \n",
       "4            Barbecue, Chinese, Mughlai, North Indian    4.1   \n",
       "5                    North Indian, Italian, Oriental     3.9   \n",
       "6                              Barbecue, North Indian    3.6   \n",
       "7                    North Indian, Chinese, Fast Food    3.9   \n",
       "8                  North Indian, Chinese, Continental    4.3   \n",
       "9                     North Indian, Mughlai, Barbecue    4.3   \n",
       "10                              North Indian, Mughlai    3.8   \n",
       "11                    North Indian, Chinese, Barbecue    4.2   \n",
       "12   Multi-Cuisine, Asian, European, Italian, Nort...      4   \n",
       "\n",
       "                                               IMAGES  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame\n",
    "DineOut=pd.DataFrame({})\n",
    "DineOut['Restaurant Name']=name\n",
    "DineOut['Location']=location\n",
    "DineOut['Price']=price \n",
    "DineOut['Cuisine']=cuisine  \n",
    "DineOut['Rating']=rating  \n",
    "DineOut['IMAGES']=images\n",
    "DineOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Write a python program to scrape the details of top publications from Google Scholar from \n",
    "https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "i) Rank \n",
    "ii) Publication\n",
    "iii) h5-index\n",
    "iv) h5-median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get(\"https://scholar.google.com/citations?view_op=top_venues&hl=en\")\n",
    "page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# page content\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "# creating empty lists\n",
    "rank = []\n",
    "publication = []\n",
    "h5Index = []\n",
    "h5Median = []\n",
    "\n",
    "# scraping rank \n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_p\"):\n",
    "    rank.append(i.text)\n",
    "\n",
    "# scraping publication    \n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_t\"):\n",
    "    publication.append(i.text)\n",
    "    \n",
    "\n",
    "# scraping h5index    \n",
    "for i in soup.find_all('a',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    h5Index.append(i.text)\n",
    "   \n",
    "# scraping h5median      \n",
    "for i in soup.find_all('span',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    h5Median.append(i.text)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5 Index</th>\n",
       "      <th>h5 Median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>414</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>410</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>391</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>356</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>345</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Frontiers in Immunology</td>\n",
       "      <td>134</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Small</td>\n",
       "      <td>134</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Nature Immunology</td>\n",
       "      <td>133</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>JAMA Oncology</td>\n",
       "      <td>133</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>The Lancet Neurology</td>\n",
       "      <td>133</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                        Publication h5 Index h5 Median\n",
       "0     1.                                             Nature      414       607\n",
       "1     2.                The New England Journal of Medicine      410       704\n",
       "2     3.                                            Science      391       564\n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...      356       583\n",
       "4     5.                                         The Lancet      345       600\n",
       "..   ...                                                ...      ...       ...\n",
       "95   96.                            Frontiers in Immunology      134       177\n",
       "96   97.                                              Small      134       173\n",
       "97   98.                                  Nature Immunology      133       210\n",
       "98   99.                                      JAMA Oncology      133       202\n",
       "99  100.                               The Lancet Neurology      133       200\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "data = list(zip(rank,publication,h5Index,h5Median))\n",
    "df = pd.DataFrame(data,columns=[\"Rank\",\"Publication\",\"h5 Index\",\"h5 Median\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
